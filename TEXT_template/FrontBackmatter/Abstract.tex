%*******************************************************
% Abstract
%*******************************************************
%\renewcommand{\abstractname}{Abstract}
\addcontentsline{toc}{chapter}{\abstractname}

\pdfbookmark[1]{Abstract}{Abstract}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Abstract}
\lettrine[lines=4]{\textcolor{purple}{T}}{he} need to crunch a steadily growing amount of data generated by the modern applications is driving an increasing demand of flexible computing power, that is more and more often satisfied by cloud computing solutions. Cloud computing has revolutionized the way computer infrastructures are abstracted and used. It is built on virtual hardware and software infrastructures accessible via the Internet and its usage is suitable for big data processing by enterprises of any size. 
Big data is a research field that deals with ways to analyze and extract information from data sets containing structured and unstructured data whose size is so large that makes the processing of data with traditional databases and applications very difficult or pratically impossible. The processing of these data therefore requires the use of distributed frameworks specialized for the parallel execution of programs, such as Apache Hadoop~\cite{misc:ApacheHadoop} and Apache Spark~\cite{misc:ApacheSpark}. These specialized frameworks are used to transform the applications in atomic parts that can be executed in a distributed cluster of physical or virtual machines. 
%The limit to the level of parallelism that can be obtained is given by the number of machines and the amount of synchronization needed between the data fragments representing the intermediate results. 
This paradigm has been historically represented by the Map-Reduce programming model firstly introduced by Google~\cite{misc:GoogleMapReduce} and subsequently implemented by the Apache Hadoop~\cite{misc:ApacheHadoop} framework. Map-Reduce consists of two distinct tasks: Map and Reduce. %As suggested by the name, the reducer phase takes place after the mapper phase has been completed. 
%A map job reads and processes a block of data to produce key-value pairs as intermediate outputs, that are input to the reducer. The reducer receives the key-value pair from multiple map jobs and then aggregates those intermediate data tuples (intermediate key-value pair) into a smaller set of tuples or key-value pairs which is the final output.
A map job reads and processes a block of data to produce key-value pairs (tuples) as intermediate outputs, that are input to the reducer. The reducer receives tuples from multiple map jobs and then aggregates those intermediate data tuples into a smaller set of tuples which is the final output.
%One of the most frequently used cluster computing frameworks for big data analytics is Apache Spark (Spark), which provides a fast and general, fault-tolerant data processing platform that allows quick in memory computation. Spark computation is based on RDDs, a data abstraction, and DAGs, representing the data manipulation processes.%
A more advanced solutions is represented by Apache Spark~\cite{misc:ApacheSpark}, that provides a greater flexibility and allows building large-scale data processing applications.
Spark uses a data sharing abstraction called Resilient Distributed Dataset (RDD). 
%When an application is submitted to Spark, an application’s driver process is created to collect the results of the computations made on the RDDs, and the application is divided in multiple jobs. Jobs are delimited by Spark actions in the application code. Spark actions are  operations that return a value to the driver program after running a computation on an RDD.
The applications are divided in multiple jobs, that are delimited by Spark actions in the application code. For each job, a Directed Acyclic Graph (DAG) or \textit{Parallel Execution Plan} (\plan), is created to keep track of the RDDs and maximize the parallelism while executing an application. 
%that are materialized inside the job. 
%DAG nodes represent the RDDs, meanwhile arcs represent transformations, that are the operations that create new datasets from existing ones. The application steps inside a single job are further organized into stages.
%, that are delimited by operations that require data reshuffling. The DAG defines the execution order among stages, and the extent to which stages can be executed in parallel. For each job, Spark computes a DAG or \textit{Parallel Execution Plan}, from now on called \plan to maximize the parallelism while executing an application. 
The parallel execution plan of the application is obtained by joining the \plans of its job.
%Spark generalizes the two stage Map-Reduce to support arbitrary \plans, and provides fast data sharing between operations by executing in-memory computing, unlike Hadoop that requires intermediate data to be written to disk in order to be accessible by the following operations.
%The main advantage of Spark with respect to previous cluster computing frameworks is the fast data sharing between operations. For example, Apache Hadoop requires intermediate data to be written to disk in order to be accessible by the following operations, Spark instead allows to execute in-memory computing. 
Big data applications pose new challenges in satisfying requirements on the \textit{Quality of Service} (\qos) provided to end users. In the world of traditional applications (e.g. web) this problem has often been faced using self-adaptive systems that control runtime \textit{KPIs} (Key Performance Indicators) (e.g.  response time) against changes in the application context and workload. %In the world of big data, the notion of \qos differ by application type. While interactive applications are usually assessed according to response time or throughput, 
%and their fulfillment depends on the intensity and variety of the incoming requests, 
Big data applications might require a single batch computation on a very large dataset, thus \qos must consider the execution of a single run. In this domain \qos is often called \textbf{deadline}, or the desired duration of the computation. Thus, users may be interested in quantifying and constraining the execution time of \textit{\textbf{every single run}} of an application. 
%Cluster computing, an implementation of the Parallel Computing paradigm composed by a large number of networked multi-cpu computers in the cloud, is widely used to speed-up application execution time. 
%Clusters of networked multi-cpu computers in the cloud, implementing the Parallel Computing paradigm, are often used to speed-up the execution of big data applications. However, a fast 
%A fast computing system alone is not enough to guarantee that a big data application will meet a fixed deadline, as the execution time depends on many variable factors such as the amount of computing resources available (cpu's, memory, storage). Since the amount of work to execute the application is not known a priori and the deadline is fixed, the system must be able to allocate resources dynamically to the application at runtime to help meeting the \qos. 
In order to meet a predefined deadline, runtime dynamic resource allocation is required, as the execution time of an application depends on many variable factors such as the amount of computing resources available (cpu's, memory, storage) available at runtime. %A fast computing system alone is not enough to guarantee that a big data application will meet a fixed deadline, as the execution time depends on many variable factors such as the amount of computing resources available (cpu's, memory, storage). Since the amount of work to execute the application is not known a priori and the deadline is fixed, the system must be able to allocate resources dynamically to the application at runtime to help meeting the \qos.

%The speed of execution of a big data application in fact depends on many factors that vary over time, such as the amount of resources available (i.e. number of cpu cores, amount of memory, storage space) or the amount of data to be processed. Since the amount of work required by the big data application is not known a priori and the deadline is fixed, the system must be capable of allocating the needed amount of resources dynamically at runtime (i.e. when they are required by the application) to meet the \qos. 
xSpark, developed at Politecnico di Milano, is an extension of the Apache Spark framework that offers fine-grained dynamic resource allocation using lightweight containers. It allows users to constrain the duration of the execution of an application by specifying a deadline. This is possible thanks to the knowledge of the application \plan, generated by running the application in profiling mode, and the runtime allocation of resources to task executors by a specialized xSpark’s control loop%, composed by a centralized heuristic and a distributed local controller.
All the above works under the assumption that the application execution flow is represented by a single \plan, which is true when the application code does not contain any conditional branch whose outcome depends on user input values or the result of previous calculations involving input data. %If the  condition of uniqueness of the application \plan is violated, xSpark
If the above condition is violated, xSpark cannot correctly control the application execution, giving incomplete or incorrect results. 
%When the application contains the above mentioned conditional branches, 
In this case, a family of application \plans (or a tree of application \plans) is needed to describe all the possible execution flows generated by the combinations of all the different branch outcomes in the application code. 
%Here is where \tool, the project described in this thesis, comes into play. 
\tool, the solution described in this thesis, extends xSpark capability to safely run multi-\plan applications, by exploiting symbolic execution. At each decisional branch outcome in the application, \tool determines which \plans are still valid and prunes the \plans tree, removing the invalid \plans, thus leaving only the valid ones in the \plans tree. A heuristic is used to select the \plan to execute among the valid ones, in order to minimize the risk of missing the deadline while maximizing the CPU usage efficiency.
\paragraph{Results}
%The solution presented in this thesis is \tool, a toolchain providing the capability to manage the efficient execution of deadline-based QoS constrained multi-\plan Spark applications. \tool is the result of the integration of \dSymb, a tool exploiting symbolic execution techniques to generate the path condition associated to each possible {\plan}s produced by different inputs and parameters, with (a modified version of) xSpark. Moreover, \tool generates a launcher with a synthesized dataset for each \plan and \textit{GuardEvaluator}, an artifact that retrieves the feasible {\plan}s given a set of symbolic variables resolved to a value. Finally, we integrated this approach with xSpark, an extension of Spark that can control the duration of Spark applications according to specified deadlines through dynamic resource allocation. 
\tool is the result of the integration of \dSymb, a tool exploiting symbolic execution to discover all possible application {\plan}s produced by different inputs and parameters, with (a modified version of) xSpark.
%We tested \tool with two applications, Promocalls, that was developed at Politecnico di Milano in the Deib Labs\footnote{\url{https://github.com/seepep/promocalls}}, a paradigmatic application resembling a daily routine of a telecommunications company for calculating the application of promotional discounts to the most active users, and Louvain, a Spark implementation of the Louvain algorithm~\cite{Louvain} that we downloaded from a highly ranked GitHub repository\footnote{\url{https://github.com/Sotera/spark-distributed-louvain-modularity}}. Louvain uses \textit{GraphX}, a Spark library specialized for graph processing, suitable for representing large user networks and analyzing communities belonging to these networks.
We tested \tool with two applications, Promocalls\footnote{\url{https://github.com/seepep/promocalls}}, and Louvain\footnote{\url{https://github.com/Sotera/spark-distributed-louvain-modularity}}, that uses \textit{GraphX}, a Spark library specialized for graph processing.
%The evaluation shows that \approach is able to effectively extract all the \plans generated by Spark applications and that \tool effectively and efficiently controls the allocation of resources during the execution of PromoCalls and Louvain, keeping the execution times within considered deadlines with significantly smaller errors and consuming a lower amount of resources than the original version of \cSpark.
The evaluation shows that \approach is able to effectively extract all the \plans generated by Spark applications and that \tool effectively and efficiently controls the allocation of resources during the execution of PromoCalls and Louvain, keeping the execution times within considered deadlines with significantly smaller errors and consuming a lower amount of resources than the original version of \cSpark.
\paragraph{Future Developments}
The applicability of the profiling contained in \tool is currently limited by the  cardinality of the set of paths to be profiled, since it requires the profiling of the entire application using a launcher specific for each path identified by \dSymb. This effort can  become practically unfeasible if the number of paths is too high. A future work could be directed at improving this part of the tool chain, by moving away from the current profiling path-based selection criteria in favour of a profiling  that uses branch-based criteria.

Another path to explore with a future work is the applicability of the proposed solution to the execution of non-strict deadlines \qos-constrained multi-\plans applications.

\vfill
\newpage
\pdfbookmark[1]{Sommario}{Sommario}
\chapter*{Sommario}
Per abstract si intende il sommario di un documento, senza l'aggiunta di interpretazioni e valutazioni. L'abstract si limita a riassumere, in un determinato numero di parole, gli aspetti fondamentali del documento esaminato. Solitamente ha forma "indicativo-schematica"; presenta cioé notizie sulla struttura del testo e sul percorso elaborativo dell'autore.

Max 2200 caratteri compresi gli spazi.

\endgroup