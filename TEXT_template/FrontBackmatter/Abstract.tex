%*******************************************************
% Abstract
%*******************************************************
%\renewcommand{\abstractname}{Abstract}
\addcontentsline{toc}{chapter}{\abstractname}

\pdfbookmark[1]{Abstract}{Abstract}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Abstract}
\lettrine[lines=4]{\textcolor{purple}{T}}{he} need to crunch a steadily growing amount of data generated by the modern applications is driving an increasing demand of flexible computing power, that is more and more often satisfied by cloud computing solutions. Cloud computing has revolutionized the way computer infrastructures are abstracted and used. It is built on abstract hardware and software infrastructures accessible via the Internet and its usage is suitable for big data processing by enterprises of any size. Big data is a massive amount of structured and unstructured data whose size is so large that it makes it very difficult, in many practical cases impossible, the processing with traditional database and software approaches. Dealing with large datasets makes it difficult to create, manipulate and manage data, especially about search and analysis. In addition, big data applications pose a new challenge to the Quality of Service (QoS) provided to users. In particular, users may be interested in quantifying and constraining the execution time of every single run of an application. Cluster computing, an implementation of the Parallel Computing paradigm composed by a large number of networked multi-cpu computers in the cloud, is widely used to speed-up application execution time. One of the most frequently used cluster computing frameworks for big data analytics is Apache Spark, which provides a fast and general, fault-tolerant data processing platform that allows quick in memory computation. Spark computation is based on RDDs, a data abstraction, and DAGs, representing the data manipulation processes. xSpark, developed at Politecnico di Milano, is an extension of the Apache Spark framework that offers fine-grained dynamic resource allocation using lightweight containers. It allows users to constrain the duration of the execution of an application by specifying a deadline. This is possible thanks to the knowledge of the application Directed Acyclic Graph (DAG), generated by running the application in profiling mode, and the runtime allocation of resources to task executors by a specialized xSpark’s control loop, composed by a centralized heuristic and a distributed local controller. All the above works under the assumption that the application execution flow is represented by a single DAG, which is true when the application code does not contain any conditional branch whose outcome depends on user input values or the result of previous calculations involving input data. When the application contains such conditional branches, a family of DAGs (or a tree of DAGs) is needed to describe all the possible execution flows corresponding to the combinations of all the different branch outcomes. Here is where xSpark-dagsymb, the project described in this thesis, comes into play. xSpark-dagsymb extends xSpark capability to safely run multi-DAG applications, by exploiting symbolic execution (techniques, principles or theory?). At each decisional branch outcome in the application, xSpark-dagsymb determines which DAGs are still valid and prunes the DAG tree, removing the invalid DAGs, thus leaving only the valid ones in the DAG tree. A heuristic is used to select the DAG to execute among the valid ones, in order to minimize the risk of missing the deadline while maximizing the CPU usage efficiency.
\vfill
\newpage
\pdfbookmark[1]{Sommario}{Sommario}
\chapter*{Sommario}
Per abstract si intende il sommario di un documento, senza l'aggiunta di interpretazioni e valutazioni. L'abstract si limita a riassumere, in un determinato numero di parole, gli aspetti fondamentali del documento esaminato. Solitamente ha forma "indicativo-schematica"; presenta cioé notizie sulla struttura del testo e sul percorso elaborativo dell'autore.

Max 2200 caratteri compresi gli spazi.

\endgroup